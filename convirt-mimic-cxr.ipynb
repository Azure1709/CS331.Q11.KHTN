{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11020923,"sourceType":"datasetVersion","datasetId":6850723},{"sourceId":14233276,"sourceType":"datasetVersion","datasetId":9080453}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport ast","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model_path = \"/kaggle/input/convirt1/pytorch/default/1\"\ndataset_path = \"/kaggle/input/mimic-cxr-dataset/official_data_iccv_final\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip install gdown\n# gdrive_link_1 = \"https://drive.google.com/uc?id=1dincSb_q9LujRshYKspn0mloX3Zm0T_y\"\n# gdrive_link_2 = \"https://drive.google.com/uc?id=1reDpwuNDeXn4Ww50qbozuQCMugf1Vo9a\"\n# !gdown {gdrive_link_1}\n# !gdown {gdrive_link_2}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model_url = \"https://drive.google.com/drive/folders/1_55_Z8f1NYMapbyzwTS3eNkkmpkTmmtX?usp=sharing\"\n# !gdown --folder \"{model_url}\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_csv_path = \"/kaggle/input/newdts2/convirt_train_sentence.csv\"\nvalidate_csv_path = \"/kaggle/input/newdts2/convirt_val_sentence.csv\"\ntrain_df = pd.read_csv(train_csv_path)\nval_df = pd.read_csv(validate_csv_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"size of train data: \", train_df.shape)\nprint(\"size of validate data: \", val_df.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"import yaml\nimport os\n\n# 1. ƒê·ªãnh nghƒ©a n·ªôi dung c·∫•u h√¨nh (Dictionary)\nconfig_data = {\n    # --- Training Hyperparameters ---\n    \"batch_size\": 64,          # Batch size v·∫≠t l√Ω (t√πy thu·ªôc VRAM GPU, 16GB VRAM th√¨ 32 ok)\n    \"accumulation_steps\": 1,   # <--- TH√äM M·ªöI: T√≠ch l≈©y 4 l·∫ßn -> Effective Batch Size = 32 * 4 = 128\n        \n    \"start_epoch\": 1,\n    \"epochs\": 11,              # SimCLR h·ªôi t·ª• kh√° l√¢u, nh∆∞ng 200 c√≥ th·ªÉ h∆°i nhi·ªÅu cho test, m√¨nh ƒë·ªÉ 50-100 t√πy b·∫°n\n    # \"progressive_unfreezing_phase\": 1, \n    \"eval_every_n_epochs\": 1,  # N√™n validate th∆∞·ªùng xuy√™n h∆°n ƒë·ªÉ check overfit s·ªõm\n    \"log_every_n_steps\": 20,\n    \"weight_decay\": 1e-4,      # 1e-3 c√≥ th·ªÉ h∆°i cao cho AdamW, th∆∞·ªùng d√πng 1e-4 ho·∫∑c 1e-6\n    \"fp16_precision\": True,    # Mixed precision gi√∫p ti·∫øt ki·ªám VRAM -> tƒÉng ƒë∆∞·ª£c batch_size\n    \"truncation\": True,\n\n    # [NEW]: Tham s·ªë cho Gradient Clipping (ƒë·ªÉ tr√°nh b√πng n·ªï gradient)\n    \"max_grad_norm\": 1.0,\n    \"patience\": 3,# D·ª´ng n·∫øu sau 10 epoch loss validation kh√¥ng gi·∫£m\n    \n    # --- Split Learning Rates ---\n    # V√¨ Effective Batch Size tƒÉng l√™n 128, ta c√≥ th·ªÉ gi·ªØ LR n√†y ho·∫∑c tƒÉng nh·∫π\n    \"learning_rate_resnet\": 3e-4,\n    \"learning_rate_bert\": 3e-5,\n    \"warmup_epochs\": 1,\n    \n    # --- Checkpoint ---\n    # QUAN TR·ªåNG: N·∫øu train m·ªõi ho√†n to√†n, h√£y ƒë·ªÉ None. \n    # N·∫øu ƒë·ªÉ ƒë∆∞·ªùng d·∫´n c≈© m√† file kh√¥ng t·ªìn t·∫°i, code train ƒë√£ c√≥ try-catch ƒë·ªÉ handle v·ªÅ train scratch.\n    \"fine_tune_from\": \"/kaggle/working/MIMIC-CXR_unfreeze_1_change_valid/runs/Dec13_07-11-09_34681e2a5120\", \n\n    # --- Model Configuration ---\n    \"model\": {\n        \"out_dim\": 512,         # Projection head dimension\n        \"res_base_model\": \"resnet50\",\n        \"bert_base_model\": \"emilyalsentzer/Bio_ClinicalBERT\",\n        \"freeze_layers\": [0, 1, 2, 3, 4, 5],\n        \"do_lower_case\": False\n    },\n\n    # --- Train Configuration ---\n    \"train\": {\n        # \"freeze_resnet\": False,\n        \"unfreeze_resnet_block\": 3,\n        \"unfreeze_bert_layer\": 2,\n        \"use_loss\": \"sigmoid\", # sigmoid or ntxent\n        \"trainable_t\": True, # only for sigmoid loss\n    },\n    \n    # --- Dataset Configuration ---\n    \"dataset\": {\n        \"s\": 1,\n        \"input_shape\": \"(224,224,3)\",\n        \"num_workers\": 4,       # Kaggle c√≥ 2-4 core CPU, ƒë·ªÉ 4 l√† ·ªïn\n        \"valid_size\": 0.1,\n        \n        \"train_csv_file\": train_csv_path,\n        \"val_csv_file\": validate_csv_path,\n        \"text_from_files\": False,\n\n        # ƒê·∫£m b·∫£o ƒë∆∞·ªùng d·∫´n n√†y ƒë√∫ng tr√™n m√¥i tr∆∞·ªùng c·ªßa b·∫°n\n        \"text_root_dir\": dataset_path,\n        \"img_root_dir\": dataset_path,\n        \n        \"img_path_col\": 1, \n        \"text_col\": 2      \n    },\n\n    # --- Loss Configuration ---\n    \"loss\": {\n        \"temperature\": 0.1,         # Quan tr·ªçng nh·∫•t trong NTXentLoss\n        \"use_cosine_similarity\": True,\n        \"alpha_weight\": 0.75\n    }\n}\n\n# 2. L∆∞u Dictionary xu·ªëng file .yml\noutput_path = \"config.yml\" \n\nwith open(output_path, 'w') as f:\n    yaml.dump(config_data, f, default_flow_style=False, sort_keys=False)\n\nprint(f\"‚úî ƒê√£ t·∫°o file c·∫•u h√¨nh m·ªõi t·∫°i: {os.path.abspath(output_path)}\")\nprint(f\"‚úî Effective Batch Size: {config_data['batch_size'] * config_data['accumulation_steps']}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom torchvision import transforms, models\nfrom transformers import AutoTokenizer, AutoModel\nfrom typing import Tuple, List, Dict, Any\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dataset Wrapper","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimport pandas as pd\nimport os\nimport random\n\nclass ClrDataset(Dataset):\n    \"\"\"Contrastive Learning Representations Dataset.\"\"\"\n\n    def __init__(self, \n                 csv_file, \n                 img_root_dir, \n                 input_shape, \n                 img_path_col, \n                 text_col, \n                 text_from_files, \n                 text_root_dir, \n                 transform=None,\n                 tokenizer=None,       # <--- Th√™m tham s·ªë n√†y\n                 max_length=512):      # <--- Th√™m tham s·ªë n√†y\n        \n        self.clr_frame = pd.read_csv(csv_file)\n        self.img_root_dir = img_root_dir\n        self.transform = transform\n        self.input_shape = input_shape\n        self.img_path_col = int(img_path_col)\n        self.text_col = int(text_col)\n        self.text_from_files = text_from_files\n        self.text_root_dir = text_root_dir\n        self.tokenizer = tokenizer     # <--- L∆∞u tokenizer\n        self.max_length = max_length   # <--- L∆∞u max_length\n\n    def __len__(self):\n        return len(self.clr_frame)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        # 1. Load Image\n        img_name = os.path.join(self.img_root_dir,\n                                self.clr_frame.iloc[idx, self.img_path_col])\n        image = Image.open(img_name)\n        if self.input_shape[2] == 3:\n            image = image.convert('RGB')\n        \n        # 2. Load Text Phrase\n        if not self.text_from_files:\n            text = self.clr_frame.iloc[idx, self.text_col]\n            # Simple cleaning\n            text = str(text).replace(\"\\n\", \"\") \n            ls_text = text.split(\".\")\n            # Filter empty strings\n            ls_text = [t for t in ls_text if t.strip()]\n            if not ls_text: # Handle case where text might be empty\n                phrase = text\n            else:\n                phrase = random.choice(ls_text)\n        else:\n            text_path = os.path.join(self.text_root_dir, \n                                     self.clr_frame.iloc[idx, self.text_col])\n            with open(text_path) as f:\n                content = f.readlines()\n            content = content[0].replace(\"\\n\", \"\")\n            ls_text = content.split(\".\")\n            ls_text = [t for t in ls_text if t.strip()]\n            if not ls_text:\n                phrase = content\n            else:\n                phrase = random.choice(ls_text)\n\n        # 3. Tokenize ngay t·∫°i ƒë√¢y (QUAN TR·ªåNG)\n        if self.tokenizer:\n            # Tokenize tr·∫£ v·ªÅ dict g·ªìm input_ids, attention_mask, ...\n            tokenized_output = self.tokenizer(\n                phrase,\n                max_length=self.max_length,\n                padding='max_length',\n                truncation=True,\n                return_tensors='pt'\n            )\n            \n            # Tokenizer m·∫∑c ƒë·ªãnh th√™m dimension batch (1, seq_len), ta c·∫ßn squeeze v·ªÅ (seq_len)\n            phrase_input = {k: v.squeeze(0) for k, v in tokenized_output.items()}\n            \n            sample = {'image': image, 'phrase': phrase_input}\n        else:\n            sample = {'image': image, 'phrase': phrase}\n\n        # 4. Transform Image\n        if self.transform:\n            # L∆∞u √Ω: SimCLRDataTransform c·∫ßn ƒë∆∞·ª£c s·ª≠a ƒë·ªÉ ch·ªâ transform image\n            # Logic ·ªü d∆∞·ªõi gi·∫£ ƒë·ªãnh transform ƒë√£ ƒë∆∞·ª£c s·ª≠a\n            sample = self.transform(sample)\n\n        return sample\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nnp.random.seed(0)\n\n\nclass GaussianBlur(object):\n    # Implements Gaussian blur as described in the SimCLR paper\n    def __init__(self, kernel_size, min=0.1, max=2.0):\n        self.min = min\n        self.max = max\n        # kernel size is set to be 10% of the image height/width\n        self.kernel_size = kernel_size\n\n    def __call__(self, sample):\n        sample = np.array(sample)\n\n        # blur the image with a 50% chance\n        prob = np.random.random_sample()\n\n        if prob < 0.5:\n            sigma = (self.max - self.min) * np.random.random_sample() + self.min\n            sample = cv2.GaussianBlur(sample, (self.kernel_size, self.kernel_size), sigma)\n\n        return sample\nimport numpy as np\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport torchvision.transforms as transforms\n\nclass DataSetWrapper(object):\n    def __init__(self, \n                batch_size, \n                num_workers, \n                valid_size, \n                input_shape, \n                s, \n                train_csv_file,\n                val_csv_file,\n                img_root_dir, \n                img_path_col, \n                text_col, \n                text_from_files, \n                text_root_dir,\n                tokenizer=None): # <--- ƒê√£ th√™m tham s·ªë tokenizer\n                \n        self.batch_size = batch_size\n        self.num_workers = num_workers\n        self.valid_size = valid_size\n        self.s = s\n        self.input_shape = eval(input_shape)\n        self.train_csv_file = train_csv_file\n        self.val_csv_file = val_csv_file\n        self.img_root_dir = img_root_dir\n        self.img_path_col = img_path_col \n        self.text_col = text_col\n        self.text_from_files = text_from_files\n        self.text_root_dir = text_root_dir\n        self.tokenizer = tokenizer # <--- L∆∞u tokenizer\n\n    def get_data_loaders(self):\n        data_augment = self._get_simclr_pipeline_transform()\n        \n        # Truy·ªÅn tokenizer v√†o ClrDataset\n        train_dataset = ClrDataset(csv_file=self.train_csv_file,\n                                    img_root_dir=self.img_root_dir,\n                                    input_shape = self.input_shape,\n                                    img_path_col = self.img_path_col, \n                                    text_col = self.text_col, \n                                    text_from_files = self.text_from_files, \n                                    text_root_dir = self.text_root_dir, \n                                    transform=SimCLRDataTransform(data_augment),\n                                    tokenizer=self.tokenizer # <--- Truy·ªÅn xu·ªëng dataset\n                                    )\n        \n        valid_dataset = ClrDataset(csv_file=self.val_csv_file,\n                                    img_root_dir=self.img_root_dir,\n                                    input_shape = self.input_shape,\n                                    img_path_col = self.img_path_col, \n                                    text_col = self.text_col, \n                                    text_from_files = self.text_from_files, \n                                    text_root_dir = self.text_root_dir, \n                                    transform=SimCLRDataTransform(data_augment),\n                                    tokenizer=self.tokenizer # <--- Truy·ªÅn xu·ªëng dataset\n                                    )\n\n        train_loader, valid_loader = self.get_train_validation_data_loaders(train_dataset, valid_dataset)\n        return train_loader, valid_loader\n\n    def _get_simclr_pipeline_transform(self):\n        # get a set of data augmentation transformations\n        data_transforms = transforms.Compose([\n                                            transforms.Resize((self.input_shape[0], self.input_shape[1])),\n                                            transforms.RandomResizedCrop(size=self.input_shape[0], scale=(0.8, 1.0)),\n                                            transforms.RandomHorizontalFlip(),\n                                            transforms.RandomGrayscale(p=0.2),\n                                            transforms.ToTensor(),\n                                            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n                                            ])\n        return data_transforms\n\n    def get_train_validation_data_loaders(self, train_dataset, valid_dataset):\n        # obtain training indices that will be used for validation\n        # num_train = len(train_dataset)\n        # indices = list(range(num_train))\n        # np.random.shuffle(indices)\n\n        # split = int(np.floor(self.valid_size * num_train))\n        # train_idx, valid_idx = indices[split:], indices[:split]\n\n        # # define samplers for obtaining training and validation batches\n        # train_sampler = SubsetRandomSampler(train_idx)\n        # valid_sampler = SubsetRandomSampler(valid_idx)\n\n        # T·ªëi ∆∞u DataLoader v·ªõi pin_memory=True\n        # train_loader = DataLoader(train_dataset, batch_size=self.batch_size, sampler=train_sampler,\n        #                           num_workers=self.num_workers, drop_last=True, shuffle=False,\n        #                           pin_memory=True)\n\n        # valid_loader = DataLoader(valid_dataset, batch_size=self.batch_size, sampler=valid_sampler,\n        #                           num_workers=self.num_workers, drop_last=True,\n        #                           pin_memory=True)\n\n        train_loader = DataLoader(train_dataset, batch_size=self.batch_size,\n                                  num_workers=self.num_workers, drop_last=True, shuffle=False,\n                                  pin_memory=True)\n\n        valid_loader = DataLoader(valid_dataset, batch_size=self.batch_size,\n                                  num_workers=self.num_workers, drop_last=True,\n                                  pin_memory=True)\n        \n        return train_loader, valid_loader\n\n\nclass SimCLRDataTransform(object):\n    def __init__(self, transform_image):\n        self.transform_image = transform_image\n\n    def __call__(self, sample):\n        xi = self.transform_image(sample['image'])\n        xl = sample['phrase']\n\n        return xi, xl\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loss function","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\n\nclass SigmoidContrastiveLoss(nn.Module):\n    def __init__(self, temperature=0.5, trainable_t = True):\n        super().__init__()\n        self.trainable_t = trainable_t\n        if trainable_t:\n            self.log_temperature = nn.Parameter(torch.zeros(1))\n            self.bias = nn.Parameter(torch.zeros(1))\n        else:\n            self.temperature = temperature\n        # self.margin = margin\n        # self.alpha = alpha\n        self.cumulative_mean_diag = 0\n        self.cumulative_top1_acc = 0\n        self.cumulative_mean_off = 0\n\n    def forward(self, z_img, z_txt):\n        z_img = F.normalize(z_img, dim=1)\n        z_txt = F.normalize(z_txt, dim=1)\n\n        logits = z_img @ z_txt.T\n        if self.trainable_t:\n            t = torch.exp(self.log_temperature)\n            logits = logits * t + self.bias\n        else:\n            logits = logits/self.temperature\n        \n        B = logits.size(0)\n\n        labels = torch.eye(B, device=logits.device) * 2 - 1\n        log_sigmoid = F.logsigmoid(labels * logits)\n        weighted_matrix = ((B-1)*torch.eye(B, device=logits.device) + 1)\n        weighted_Loss = -log_sigmoid * weighted_matrix\n        sigmoid_loss = weighted_Loss.mean()\n\n        diag = logits.diag()\n        # print(\"mean diag: \", diag.mean())\n        self.cumulative_mean_diag += diag.mean()\n        top1 = (logits.argmax(dim=1) == torch.arange(B, device=logits.device)).float().mean()\n        # print(\"top1 acc: \", top1)\n        self.cumulative_top1_acc += top1\n        off  = logits[~torch.eye(B, dtype=bool, device=logits.device)]\n        self.cumulative_mean_off += off.mean()\n\n        return sigmoid_loss\n\n        # pos_constraint = F.relu(-logits.diag()).mean()\n        # return sigmoid_loss + 0.5 * pos_constraint\n\n\nclass SigLipLoss(nn.Module):\n    \"\"\" Sigmoid Loss for Language Image Pre-Training (SigLIP) - https://arxiv.org/abs/2303.15343\n\n    @article{zhai2023sigmoid,\n      title={Sigmoid loss for language image pre-training},\n      author={Zhai, Xiaohua and Mustafa, Basil and Kolesnikov, Alexander and Beyer, Lucas},\n      journal={arXiv preprint arXiv:2303.15343},\n      year={2023}\n    }\n    \"\"\"\n    def __init__(\n            self,\n            cache_labels=False,\n            rank=0,\n            world_size=1,\n            bidir=True,\n            use_horovod=False,\n    ):\n        super().__init__()\n        self.cache_labels = cache_labels\n        self.rank = rank\n        self.world_size = world_size\n        assert not use_horovod  # FIXME need to look at hvd ops for ring transfers\n        self.use_horovod = use_horovod\n        self.bidir = bidir\n\n        # cache state FIXME cache not currently used, worthwhile?\n        self.prev_num_logits = 0\n        self.labels = {}\n\n        self.cumulative_mean_diag = 0\n        self.cumulative_top1_acc = 0\n        self.cumulative_mean_off = 0\n\n    def get_ground_truth(self, device, dtype, num_logits, negative_only=False) -> torch.Tensor:\n        labels = -torch.ones((num_logits, num_logits), device=device, dtype=dtype)\n        if not negative_only:\n            labels = 2 * torch.eye(num_logits, device=device, dtype=dtype) + labels\n        return labels\n\n    def get_logits(self, image_features, text_features, logit_scale, logit_bias=None):\n        logits = logit_scale * image_features @ text_features.T\n        if logit_bias is not None:\n            logits += logit_bias\n        return logits\n\n    \n    def _loss(self, image_features, text_features, logit_scale, logit_bias=None, negative_only=False):\n        logits = self.get_logits(image_features, text_features, logit_scale, logit_bias)\n        labels = self.get_ground_truth(\n            image_features.device,\n            image_features.dtype,\n            image_features.shape[0],\n            negative_only=negative_only,\n        )\n        \n        loss = -F.logsigmoid(labels * logits).sum() / image_features.shape[0]\n\n        B = image_features.shape[0]\n        diag = logits.diag()\n        # print(\"mean diag: \", diag.mean())\n        self.cumulative_mean_diag += diag.mean()\n        top1 = (logits.argmax(dim=1) == torch.arange(B, device=logits.device)).float().mean()\n        # print(\"top1 acc: \", top1)\n        self.cumulative_top1_acc += top1\n        off  = logits[~torch.eye(B, dtype=bool, device=logits.device)]\n        self.cumulative_mean_off += off.mean()\n            \n        return loss\n\n    def forward(self, image_features, text_features, logit_scale, logit_bias, output_dict=False):\n        image_features = F.normalize(image_features, dim=-1)\n        text_features  = F.normalize(text_features, dim=-1)\n\n        loss = self._loss(image_features, text_features, logit_scale, logit_bias)\n\n        if self.world_size > 1:\n            # exchange text features w/ neighbour world_size - 1 times\n            right_rank = (self.rank + 1) % self.world_size\n            left_rank = (self.rank - 1 + self.world_size) % self.world_size\n            if self.bidir:\n                text_features_to_right = text_features_to_left = text_features\n                num_bidir, remainder = divmod(self.world_size - 1, 2)\n                for i in range(num_bidir):\n                    text_features_recv = neighbour_exchange_bidir_with_grad(\n                        left_rank,\n                        right_rank,\n                        text_features_to_left,\n                        text_features_to_right,\n                    )\n\n                    for f in text_features_recv:\n                        loss += self._loss(\n                            image_features,\n                            f,\n                            logit_scale,\n                            logit_bias,\n                            negative_only=True,\n                        )\n                    text_features_to_left, text_features_to_right = text_features_recv\n\n                if remainder:\n                    text_features_recv = neighbour_exchange_with_grad(\n                        left_rank, right_rank, text_features_to_right)\n\n                    loss += self._loss(\n                        image_features,\n                        text_features_recv,\n                        logit_scale,\n                        logit_bias,\n                        negative_only=True,\n                    )\n            else:\n                text_features_to_right = text_features\n                for i in range(self.world_size - 1):\n                    text_features_from_left = neighbour_exchange_with_grad(\n                        left_rank, right_rank, text_features_to_right)\n\n                    loss += self._loss(\n                        image_features,\n                        text_features_from_left,\n                        logit_scale,\n                        logit_bias,\n                        negative_only=True,\n                    )\n                    text_features_to_right = text_features_from_left\n\n        return {\"contrastive_loss\": loss} if output_dict else loss\n\n\nclass NTXentLoss(torch.nn.Module):\n\n    def __init__(self, device, batch_size, temperature, use_cosine_similarity, alpha_weight):\n        super(NTXentLoss, self).__init__()\n        self.batch_size = batch_size\n        self.temperature = temperature\n        self.alpha_weight = alpha_weight\n        self.device = device\n        self.softmax = torch.nn.Softmax(dim=-1)\n        self.criterion = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n        self.cumulative_top1_acc = 0 \n        self.cumulative_mean_diag = 0\n        self.cumulative_mean_off = 0\n\n    def softXEnt(self, target, logits):\n        \"\"\" \n        From the pytorch discussion Forum:\n        https://discuss.pytorch.org/t/soft-cross-entropy-loss-tf-has-it-does-pytorch-have-it/69501 \n        \"\"\"\n        logprobs = torch.nn.functional.log_softmax(logits, dim = 1)\n        loss = -(target * logprobs).sum() / logits.shape[0]\n        return loss\n\n    def forward(self, zis, zjs,\n                    norm=True,\n                    weights=1.0):\n        temperature = self.temperature\n        alpha = self.alpha_weight\n\n        # Get (normalized) hidden1 and hidden2.\n        if norm:\n            zis = F.normalize(zis, p=2, dim=1)\n            zjs = F.normalize(zjs, p=2, dim=1)\n            \n        hidden1, hidden2 = zis, zjs\n        B = hidden1.shape[0] # batch size\n\n        hidden1_large = hidden1\n        hidden2_large = hidden2\n        labels = F.one_hot(torch.arange(start=0, end=B, dtype=torch.int64), num_classes=B).float()\n        labels = labels.to(self.device)\n        masks = F.one_hot(torch.arange(start=0, end=B, dtype=torch.int64), num_classes=B)\n        \n        logits_ab = torch.matmul(hidden1, torch.transpose(hidden2_large,0, 1)) / temperature\n        logits_ba = torch.matmul(hidden2, torch.transpose(hidden1_large,0, 1)) / temperature\n\n        # get debug metric\n        diag = logits_ab.diag()\n        # print(\"mean diag: \", diag.mean())\n        self.cumulative_mean_diag += diag.mean()\n        top1 = (logits_ba.argmax(dim=1) == torch.arange(B, device=logits_ba.device)).float().mean()\n        # print(\"top1 acc: \", top1)\n        self.cumulative_top1_acc += top1\n        off  = logits_ab[~torch.eye(B, dtype=bool, device=logits_ab.device)]\n        self.cumulative_mean_off += off.mean()\n\n        loss_a = self.softXEnt(labels, logits_ab)\n        loss_b = self.softXEnt(labels, logits_ba)\n\n        return alpha*loss_a + (1-alpha)*loss_b\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"\"\"\"\nReference for BERT Sentence Embeddings method\n\n@inproceedings{reimers-2019-sentence-bert,\n    title = \"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\",\n    author = \"Reimers, Nils and Gurevych, Iryna\",\n    booktitle = \"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing\",\n    month = \"11\",\n    year = \"2019\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"http://arxiv.org/abs/1908.10084\",\n\n\"\"\"\n\nimport torchvision.models as models\nfrom transformers import AutoModel\n\n# Create the BertClassfier class\nclass ModelCLR(nn.Module):\n    def __init__(self, res_base_model, bert_base_model, out_dim, freeze_layers, do_lower_case):\n        super(ModelCLR, self).__init__()\n        # BERT base\n        self.bert_model = self._get_bert_basemodel(bert_base_model, freeze_layers)\n        # projection MLP for BERT\n        # self.bert_l1 = nn.Linear(768, 768)\n        # self.bert_l2 = nn.Linear(768, out_dim)\n        self.bert_proj = nn.Sequential(\n            nn.Linear(768, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024, out_dim)\n        )\n\n\n        # ResNet base (store the original resnet to access layer names)\n        self.resnet_dict = {\n            \"resnet18\": models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1),\n            \"resnet50\": models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n        }\n        resnet = self._get_res_basemodel(res_base_model)\n        self.resnet = resnet  # keep original model\n\n        num_ftrs = resnet.fc.in_features\n        self.res_features = nn.Sequential(*list(resnet.children())[:-1])\n        # projection MLP for ResNet Model\n        # self.res_l1 = nn.Linear(num_ftrs, 768)\n        # self.res_l2 = nn.Linear(768, out_dim)\n        self.res_proj = nn.Sequential(\n            nn.Linear(num_ftrs, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024, out_dim)\n        )\n\n\n        # --- Freeze full backbone by default ---\n        # Freeze all ResNet parameters\n        for param in self.resnet.parameters():\n            param.requires_grad = False\n        # Set batchnorm layers in resnet to eval mode to avoid updating running stats\n        for m in self.resnet.modules():\n            if isinstance(m, nn.BatchNorm2d):\n                m.eval()\n\n        # Freeze full BERT encoder optionally (we may still want to train bert_l1/bert_l2)\n        for param in self.bert_model.parameters():\n            param.requires_grad = False\n\n    def _get_res_basemodel(self, res_model_name):\n        try:\n            res_model = self.resnet_dict[res_model_name]\n            print(\"Image feature extractor:\", res_model_name)\n            return res_model\n        except:\n            raise (\"Invalid model name. Check the config file and pass one of: resnet18 or resnet50\")\n\n    def _get_bert_basemodel(self, bert_model_name, freeze_layers):\n        try:\n            model = AutoModel.from_pretrained(bert_model_name)#, return_dict=True)\n            print(\"Image feature extractor:\", bert_model_name)\n        except:\n            raise (\"Invalid model name. Check the config file and pass a BERT model from transformers lybrary\")\n\n        if freeze_layers is not None:\n            for layer_idx in freeze_layers:\n                for param in list(model.encoder.layer[layer_idx].parameters()):\n                    param.requires_grad = False\n        return model\n\n    def unfreeze_resnet_last_n_blocks(self, n=1):\n        \"\"\"\n        Unfreeze last `n` residual layers (layer4, layer3, ...).\n        n=1 => layer4; n=2 => layer4+layer3\n        \"\"\"\n        layers = []\n        # ResNet layers are named layer1, layer2, layer3, layer4\n        for i in range(4, 0, -1):  # 4,3,2,1\n            layers.append(f\"layer{i}\")\n        for name in layers[:n]:\n            layer = getattr(self.resnet, name)\n            for param in layer.parameters():\n                param.requires_grad = True\n            for m in layer.modules():\n                if isinstance(m, nn.BatchNorm2d):\n                    m.train()\n\n    def unfreeze_bert_last_n_layers(self, n=1):\n        \"\"\"\n        Unfreeze the last n encoder layers of BERT (`self.bert_model.encoder.layer`).\n        n=1 => last layer only.\n        \"\"\"\n        encoder = self.bert_model.encoder\n        total = len(encoder.layer)\n        print(\"total number of bert layer: \", total)\n        if n > total:\n            n = total\n        for i in range(total - n, total):\n            for param in encoder.layer[i].parameters():\n                param.requires_grad = True\n        # If you unfreeze BERT layers, keep bert_model in train() mode when training\n\n    \n    def mean_pooling(self, model_output, attention_mask):\n        \"\"\"\n        Mean Pooling - Take attention mask into account for correct averaging\n        Reference: https://www.sbert.net/docs/usage/computing_sentence_embeddings.html\n        \"\"\"\n        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n        return sum_embeddings / sum_mask\n\n    def image_encoder(self, xis):\n        h = self.res_features(xis)   # [B, C, 1, 1]\n        h = torch.flatten(h, 1)      # [B, C]\n    \n        # x = self.res_l1(h)\n        # x = F.relu(x)\n        # x = self.res_l2(x)\n        x = self.res_proj(h)\n        return h, x\n\n\n    def text_encoder(self, encoded_inputs):\n        outputs = self.bert_model(**encoded_inputs)\n        sentence_embeddings = self.mean_pooling(outputs, encoded_inputs['attention_mask'])\n        # x = self.bert_l1(sentence_embeddings)\n        # x = F.relu(x)\n        # out_emb = self.bert_l2(x)\n        out_emb = self.bert_proj(sentence_embeddings)\n        return out_emb\n\n    \n\n    def forward(self, xis, encoded_inputs):\n\n        h, zis = self.image_encoder(xis)\n\n        zls = self.text_encoder(encoded_inputs)\n\n        return zis, zls\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import logging\nimport shutil\nimport os\nimport yaml\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch.cuda.amp import GradScaler, autocast\nfrom torch.utils.tensorboard import SummaryWriter\nfrom tqdm import tqdm\nfrom time import time\n\n# Import Transformers\nfrom transformers import AutoTokenizer, get_cosine_schedule_with_warmup\n\n# --- C·∫§U H√åNH LOGGING ---\nlogging.getLogger(\"transformers.tokenization_utils_base\").setLevel(logging.ERROR)\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\ntorch.manual_seed(0)\n\n# --- HELPER FUNCTION ---\ndef _save_config_file(model_checkpoints_folder):\n    if not os.path.exists(model_checkpoints_folder):\n        os.makedirs(model_checkpoints_folder)\n        if os.path.exists(\"/kaggle/working/config.yml\"):\n            shutil.copy(\"/kaggle/working/config.yml\", os.path.join(model_checkpoints_folder, \"config.yml\"))\n\ndef count_trainable_params(model):\n    total = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(\"Trainable params:\", total)\n    # for name, p in model.named_parameters():\n    #     if p.requires_grad:\n    #         print(name, p.shape)\n\n\n# ==========================================\n# 1. CH√àN CLASS EARLY STOPPING T·∫†I ƒê√ÇY\n# ==========================================\nclass EarlyStopping:\n    \"\"\"D·ª´ng training s·ªõm n·∫øu validation loss kh√¥ng c·∫£i thi·ªán sau m·ªôt s·ªë epoch.\"\"\"\n    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.trace_func = trace_func\n\n    def __call__(self, val_loss, model):\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model):\n        '''L∆∞u model khi validation loss gi·∫£m.'''\n        if self.verbose:\n            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss\n\n# ==========================================\n# 2. CLASS CH√çNH (SIMCLR)\n# ==========================================\nclass SimCLR(object):\n    def __init__(self, dataset, config):\n        self.config = config\n        self.device = self._get_device()\n        self.writer = SummaryWriter()\n        self.dataset = dataset\n        if config[\"train\"][\"use_loss\"] == \"ntxent\":\n            self.loss_function = NTXentLoss(\n                self.device, config[\"batch_size\"], **config[\"loss\"]\n            )\n            print(\"simCLR using ntxent loss\")\n        elif config[\"train\"][\"use_loss\"] == \"sigmoid\":\n            self.loss_function = SigmoidContrastiveLoss(\n                config[\"loss\"][\"temperature\"], config[\"train\"][\"trainable_t\"]\n            ).to(self.device)\n            # self.loss_function = SigLipLoss()\n            # self.log_temperature = nn.Parameter(torch.zeros(1)).to(self.device)\n            # self.bias = nn.Parameter(torch.zeros(1)).to(self.device)\n            print(\"simCLR using Sigmoid loss\")\n        self.unfreeze_nesnet_block = config[\"train\"][\"unfreeze_resnet_block\"]\n        self.unfreeze_bert_layer = config[\"train\"][\"unfreeze_bert_layer\"]\n        self.truncation = config[\"truncation\"]\n\n    def _get_device(self):\n        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        print(\"Running on:\", device)\n        return device\n\n    @staticmethod\n    def build_optimizer_for_finetune(model, config):\n        # 1. L·∫•y tham s·ªë c·ªßa Backbone (ResNet v√† BERT)\n        # L∆∞u √Ω: Ki·ªÉm tra xem model c·ªßa b·∫°n d√πng t√™n 'resnet' hay 'visual_encoder'\n        # N·∫øu code d∆∞·ªõi b√°o l·ªói ti·∫øp ·ªü d√≤ng resnet, h√£y ƒë·ªïi th√†nh model.visual_encoder\n        try:\n            resnet_params = list(model.resnet.parameters())\n        except AttributeError:\n            # Fallback n·∫øu t√™n bi·∫øn kh√°c\n            resnet_params = list(model.visual_encoder.parameters()) if hasattr(model, 'visual_encoder') else []\n\n        try:\n            bert_params = list(model.bert_model.parameters())\n        except AttributeError:\n            bert_params = list(model.text_encoder.parameters()) if hasattr(model, 'text_encoder') else []\n        \n        # 2. T√¨m tham s·ªë c·ªßa Head b·∫±ng c√°ch lo·∫°i tr·ª´ Backbone ra kh·ªèi to√†n b·ªô Model\n        # (C√°ch n√†y ch·∫°y ƒë√∫ng b·∫•t k·ªÉ b·∫°n ƒë·∫∑t t√™n Head l√† res_l1, projector, hay classifier)\n        backbone_param_ids = set(map(id, resnet_params)) | set(map(id, bert_params))\n        \n        head_params = [p for p in model.parameters() if id(p) not in backbone_param_ids and p.requires_grad]\n        \n        # L·ªçc l·∫°i backbone ch·ªâ l·∫•y nh·ªØng layer kh√¥ng b·ªã freeze (requires_grad=True)\n        resnet_params = [p for p in resnet_params if p.requires_grad]\n        bert_params = [p for p in bert_params if p.requires_grad]\n\n        # 3. Thi·∫øt l·∫≠p Learning Rate\n        head_lr = config[\"learning_rate_resnet\"] # Head th∆∞·ªùng train c√πng t·ªëc ƒë·ªô v·ªõi ResNet\n        res_lr = config[\"learning_rate_resnet\"]\n        bert_lr = config[\"learning_rate_bert\"]\n        weight_decay = config[\"weight_decay\"]\n        \n        print(f\"‚úî Optimizer setup: Head ({len(head_params)} params), ResNet ({len(resnet_params)} params), BERT ({len(bert_params)} params)\")\n        \n        param_groups = []\n        if len(head_params) > 0:\n            param_groups.append({'params': head_params, 'lr': head_lr, 'weight_decay': weight_decay})\n        if len(resnet_params) > 0:\n            param_groups.append({'params': resnet_params, 'lr': res_lr, 'weight_decay': weight_decay})\n        if len(bert_params) > 0:\n            param_groups.append({'params': bert_params, 'lr': bert_lr, 'weight_decay': weight_decay})\n\n        optimizer = torch.optim.AdamW(param_groups)\n        return optimizer\n\n    def train(self):\n        train_loader, valid_loader = self.dataset.get_data_loaders()\n\n        model = ModelCLR(**self.config[\"model\"]).to(self.device)\n        model = self._load_pre_trained_weights(model)\n\n        if self.unfreeze_nesnet_block:\n            model.unfreeze_resnet_last_n_blocks(n=self.unfreeze_nesnet_block)\n        if self.unfreeze_bert_layer:\n            model.unfreeze_bert_last_n_layers(n=self.unfreeze_bert_layer)\n\n        count_trainable_params(model)\n\n        optimizer = self.build_optimizer_for_finetune(model, self.config)\n        \n        accumulation_steps = self.config.get(\"accumulation_steps\", 1) \n        max_grad_norm = self.config.get(\"max_grad_norm\", 1.0) \n\n        num_update_steps_per_epoch = len(train_loader) // accumulation_steps\n        if len(train_loader) % accumulation_steps != 0:\n            num_update_steps_per_epoch += 1\n\n        total_steps = num_update_steps_per_epoch * self.config[\"epochs\"]\n        warmup_epochs = self.config.get(\"warmup_epochs\", 1)\n        warmup_steps = num_update_steps_per_epoch * warmup_epochs\n        \n        scheduler = get_cosine_schedule_with_warmup(\n            optimizer, \n            num_warmup_steps=warmup_steps, \n            num_training_steps=total_steps\n        )\n\n        scaler = GradScaler()\n        model_checkpoints_folder = os.path.join(self.writer.log_dir, \"checkpoints\")\n        _save_config_file(model_checkpoints_folder)\n\n        # --- KH·ªûI T·∫†O EARLY STOPPING ---\n        patience = self.config.get(\"patience\", 10) \n        save_path = os.path.join(model_checkpoints_folder, \"model.pth\")\n        \n        early_stopping = EarlyStopping(\n            patience=patience, \n            verbose=True, \n            path=save_path\n        )\n\n        n_iter = 0\n        valid_n_iter = 0\n        \n        print(f\"Training with Differential LR: BERT={self.config.get('learning_rate_bert')}, ResNet={self.config.get('learning_rate_resnet')}\")\n        print(f\"Accumulation steps: {accumulation_steps}\")\n        print(f\"Early Stopping Patience: {patience}\")\n\n        for epoch_counter in range(self.config[\"start_epoch\"], self.config[\"epochs\"]):\n            epoch_loss = 0.0\n            num_batches = 0\n            optimizer.zero_grad()\n\n            for batch_idx, (xis, xls) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch_counter}\")):\n                # st = time()\n                xis = xis.to(self.device)\n                # print(\"time to transfer xis to GPU: \", time() - st)\n                # st = time()\n                input_ids = xls['input_ids'].to(self.device)\n                # print(\"time to transfer xls to GPU: \", time() - st)\n                # st = time()\n                attention_mask = xls['attention_mask'].to(self.device)\n                # print(\"time to mask attention: \", time() - st)\n                # st = time()\n                encoded_inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n                if 'token_type_ids' in xls:\n                     encoded_inputs['token_type_ids'] = xls['token_type_ids'].to(self.device)\n                # print(\"time to encode input: \", time() - st)\n                # st = time()\n                with autocast():\n                    zis, zls = model(xis, encoded_inputs)\n                    # logit_scale = self.log_temperature.exp()\n                    # loss = self.loss_function(zis, zls, logit_scale, self.bias)\n                    loss = self.loss_function(zis, zls)\n\n                    # loss = loss / accumulation_steps\n\n                scaler.scale(loss).backward()\n\n                is_last_batch = (batch_idx + 1) == len(train_loader)\n                should_update = ((batch_idx + 1) % accumulation_steps == 0) or is_last_batch\n\n                if should_update:\n                    scaler.unscale_(optimizer)\n                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n\n                    scaler.step(optimizer)\n                    scaler.update()\n                    scheduler.step()\n                    optimizer.zero_grad()\n                    \n                    current_loss = loss.item() * accumulation_steps\n                    if n_iter % self.config[\"log_every_n_steps\"] == 0:\n                        self.writer.add_scalar(\"train_loss\", current_loss, global_step=n_iter)\n                        self.writer.add_scalar(\"lr_head\", optimizer.param_groups[0]['lr'], global_step=n_iter)\n                    n_iter += 1\n\n                epoch_loss += loss.item() * accumulation_steps\n                num_batches += 1            \n\n            retrival_acc = self.loss_function.cumulative_top1_acc/num_batches \n            print(\"top1 retrival acc: \", retrival_acc)\n            self.loss_function.cumulative_top1_acc = 0\n            self.writer.add_scalar(\"top1_retrival_acc\", retrival_acc, global_step=epoch_counter)\n\n            mean_logits_diag = self.loss_function.cumulative_mean_diag/num_batches\n            print(\"mean diag: \",mean_logits_diag)\n            self.writer.add_scalar(\"mean_logits_diag\", mean_logits_diag, global_step=epoch_counter)\n            self.loss_function.cumulative_mean_diag = 0\n\n            mean_logits_off = self.loss_function.cumulative_mean_off/num_batches\n            print(\"mean off: \",mean_logits_off)\n            self.writer.add_scalar(\"mean_logits_off\", mean_logits_off, global_step=epoch_counter)\n            self.loss_function.cumulative_mean_off = 0\n            \n            cosine_sim = F.cosine_similarity(zis,zls).mean().item()\n            print(\"cosine:\", cosine_sim)\n            self.writer.add_scalar(\"cosine\", cosine_sim, global_step=epoch_counter)\n\n            epoch_mean_loss = epoch_loss / num_batches\n            print(f\"Epoch {epoch_counter} ------ Train Loss: {epoch_mean_loss:.4f}\")\n            self.writer.add_scalar(\"epoch_train_loss\", epoch_mean_loss, global_step=epoch_counter)\n\n            # --- VALIDATION & EARLY STOPPING ---\n            if epoch_counter % self.config[\"eval_every_n_epochs\"] == 0:\n                valid_loss = self._validate(model, valid_loader)\n                print(f\"Validation {epoch_counter} - Valid Loss: {valid_loss:.4f}\")\n                self.writer.add_scalar(\"validation_loss\", valid_loss, global_step=valid_n_iter)\n                valid_n_iter += 1\n                \n                # G·ªçi Early Stopping (n√≥ t·ª± l∆∞u model n·∫øu t·ªët h∆°n)\n                early_stopping(valid_loss, model)\n                \n                if early_stopping.early_stop:\n                    print(\"üöÄ  Early stopping triggered! Training stopped.\")\n                    break\n\n    def _load_pre_trained_weights(self, model):\n        try:\n            checkpoints_folder = os.path.join(\"./runs\", self.config[\"fine_tune_from\"], \"checkpoints\")\n            model_path = os.path.join(checkpoints_folder, \"model.pth\")\n            if os.path.exists(model_path):\n                state_dict = torch.load(model_path, map_location=self.device)\n                model.load_state_dict(state_dict)\n                print(\"Loaded pre-trained model with success.\")\n            else:\n                print(\"Pre-trained weights file not found. Training from scratch.\")\n        except Exception as e:\n            print(f\"Exception loading weights: {e}. Training from scratch.\")\n        return model\n\n    def _validate(self, model, valid_loader):\n        with torch.no_grad():\n            model.eval()\n            valid_loss = 0.0\n            counter = 0\n            for xis, xls in tqdm(valid_loader, desc=\"Validating\"):\n                xis = xis.to(self.device)\n                input_ids = xls['input_ids'].to(self.device)\n                attention_mask = xls['attention_mask'].to(self.device)\n                encoded_inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n                if 'token_type_ids' in xls:\n                     encoded_inputs['token_type_ids'] = xls['token_type_ids'].to(self.device)\n\n                zis, zls = model(xis, encoded_inputs)\n                # logit_scale = self.log_temperature.exp()\n                # loss = self.loss_function(zis, zls, logit_scale, self.bias)\n                loss = self.loss_function(zis, zls)\n                \n                valid_loss += loss.item()\n                counter += 1\n            \n            if counter > 0:\n                valid_loss /= counter\n                \n            cosine_sim = F.cosine_similarity(zis,zls).mean().item()\n            print(\"cosine:\", cosine_sim)\n            \n        model.train()\n        return valid_loss\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def main():\n    config = yaml.load(open(\"/kaggle/working/config.yml\", \"r\"), Loader=yaml.FullLoader)\n    \n    # Init tokenizer ·ªü ƒë√¢y\n    tokenizer = AutoTokenizer.from_pretrained(config[\"model\"][\"bert_base_model\"])\n    \n    # Truy·ªÅn tokenizer v√†o DataSetWrapper\n    dataset = DataSetWrapper(config['batch_size'], **config['dataset'], tokenizer=tokenizer)\n\n    simclr = SimCLR(dataset, config)\n    simclr.train()\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}